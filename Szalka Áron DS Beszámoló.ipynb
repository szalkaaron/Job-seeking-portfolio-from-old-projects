{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SZALKA ÁRON DATA SCIENCE kurzus beszámoló SZISZ 2023.\n",
    "\n",
    "A beszámolóban filmkritikákat töltöttem le web-scraping segítségével, a kritikákat elemeztem és vizualizáltam, majd megpróbáltam olyan modellt építeni, ami megbecsüli, hogy az adott kritika melyik oldalon jelenhetett meg.\n",
    "\n",
    "A beszámoló első része az adatok letöltése. Az imdb top 5 filmjéhez töltöttem le az össze user review-t az IMDB-ről, Rotten tomatoes-ról és a Letterboxd-ról (több, mint 5filmet szerettem volna eredetileg, de nagyon sok kritika volt már 5 filmhez is, és nagyon hosszúak voltak a letöltési idők). Ez így körülbelül 180 ezer kritia letöltését jelentette, amit megnehezített, hogy az IMDB és a Rotten Tomatoes oldalán csak Seleniummal lehetett elérni az összes kritikát, de ezek az oldalak néha elérhetetlenné váltak a próbálkozásaim után (feltételezem valami túlterhelésgátlóval védekeznek?), így többször is kellett próbálkozni minden filmnél. Mindegyik kritikához letöltöttem, hogy hány csillagot adott az adott kritika a filmre, ha értékelte. Ezeket az adatokat mind külön pickle-ökbe mentettem, és csatolom a beszámolóhoz. \n",
    "\n",
    "A dolgozat második részében az így szerzett adatokat beolvastam a picke-ökből és elrendeztem egy Pandas Dataframe-be, tisztítottam és vizualizáltam. Itt már kiderült néhány probléma, elsősorban, hogy az adatok között nics túl nagy szórás. Az értékelések szinte minden esetben 9-10 körül vannak, a kritikák hossza AZ IMDB esetében eltérő ugyan valamennyire, de a másik két oldalon nagyon hasonlóan rövidek. Ezenfelül az adatok sem oszlanak meg egyenlően az oldalak között, a Rotten Tomatoes oldalon sokkal több kritika jelent meg mint a többin. \n",
    "\n",
    "Végül a dolgozat utolsó részében megépítettem egy predikciós modellt. Sajnos sem ez, sem egyik korábbi próbálkozásom sem haladta meg nagyon sokkal az az arányt, amelyet a Rotten Tomatoes önmagában képvisel a reviewk számát tekintve. Amikor azt lecsökkentettem, akkor sem let jobb. Az a gyanúm, hogy a Rotten Tomatoes és a Letterboxd user review-i nagyon hasonlóak. Mindazonáltal a modell így is képes felülmúlni azt a józan paraszti logikát, hogy amennyiben egy kritika hosszú, akkor IMDB, egyébként Rotten Tomatoes, hiszen abból több van, mint Letterboxed-ból. Ezt a cofusion matrix is megerősíti, így kijelenthető, hogy volt értelme a modellnek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importálás. A végső modellben nem használtam mindet az importáltak közül, de nem törötlem ki utólag azokat sem, hogy emlékezzek mikkel próbálkoztam. A kódban viszont csak a legjobb prediktív erejű modellt hagytam benne.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from textblob import TextBlob\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Az IMDB toplista websrcapelése, és a címek segítségével mindhárom kritika oldal linklistájának megalkotása\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "headers = {\"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"class\": \"chart full-width\"})\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "imdbtitlelist = []\n",
    "imdblinklistelő = []\n",
    "\n",
    "for row in rows[1:]:\n",
    "    title_column = row.find(\"td\", {\"class\": \"titleColumn\"})\n",
    "    movie_title = title_column.a.text.strip()\n",
    "    imdbtitlelist = imdbtitlelist + [movie_title]\n",
    "    link_sor = row.find(\"a\")\n",
    "    link = link_sor[\"href\"]\n",
    "    imdblinklistelő = imdblinklistelő + [link]\n",
    "\n",
    "imdblinklist = [\"https://www.imdb.com\" + title + \"reviews?ref_=tt_urv\" for title in imdblinklistelő]\n",
    "\n",
    "letterboxdtitlelist = [title.replace(\" \", \"-\") for title in imdbtitlelist]\n",
    "letterboxdtitlelist = [title.lower() for title in letterboxdtitlelist]\n",
    "letterboxdlinklist = [\"https://letterboxd.com/film/\" + title + \"/reviews/\" for title in letterboxdtitlelist]\n",
    "\n",
    "rottentitlelist = [title.replace(\" \", \"_\") for title in imdbtitlelist]\n",
    "rottentitlelist = [title.lower() for title in rottentitlelist]\n",
    "rottenlinklist = [\"https://www.rottentomatoes.com/m/\" + title + \"/reviews?type=user\" for title in rottentitlelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDB egy adott filmhez tartozó összes review letöltése Seleniummal.\n",
    "#Sajnos loopolni nem sikerült, mert valószínűleg az IMDB ezt blokkolja (többször 404-et írt ki az ilyen próbálkozásaim után mikörben a többi honlap bejött).\n",
    "\n",
    "path_to_chromedriver = 'I:/Eszkozok/Chromedriver/chromedriver.exe'  \n",
    "service = Service(path_to_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.imdb.com/title/tt0050083/reviews?ref_=tt_urv\")\n",
    "wait = WebDriverWait(driver, 100)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//button[contains(@class, 'ipl-load-more__button') and @data-target-container='reviews-container' and @id='load-more-trigger']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        wait.until(EC.visibility_of_all_elements_located((By.CLASS_NAME, \"lister-item-content\")))\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "lista3 = []\n",
    "\n",
    "reviews = soup.find_all(\"div\", class_=\"lister-item mode-detail imdb-user-review collapsable\")\n",
    "        \n",
    "for review in reviews:\n",
    "    if review.find('span', class_='rating-other-user-rating') is not None:\n",
    "        darab = review.find('span', class_='rating-other-user-rating').find('span').get_text()\n",
    "    else:\n",
    "        darab = \"Na\"\n",
    "        \n",
    "        \n",
    "    if review.find(\"div\", class_=\"text show-more__control\") is not None:\n",
    "        review_text = review.find(\"div\", class_=\"text show-more__control\").get_text().strip()\n",
    "    elif review.find(\"div\", class_=\"text show-more__control clickable\") is not None:\n",
    "        review_text = review.find(\"div\", class_=\"text show-more__control clickable\").get_text().strip()\n",
    "    else:\n",
    "        review_text = \"Na\"\n",
    "    lista3 = lista3 + [[darab, review_text]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDB webscrape picke-be mentése\n",
    "\n",
    "with open('12 Angry Men Reviews IMDB.pkl', 'wb') as file:\n",
    "    pickle.dump(lista3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Egy Rotten tomates filmhez az összes review letöltése Seleniummal\n",
    "\n",
    "path_to_chromedriver = 'I:/Eszkozok/Chromedriver/chromedriver.exe'  \n",
    "service = Service(path_to_chromedriver)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.rottentomatoes.com/m/1000013_12_angry_men/reviews?type=user\")\n",
    "lista = []\n",
    "\n",
    "while True:\n",
    "   \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    reviews = soup.find_all(\"div\", class_=\"audience-review-row\")\n",
    "    \n",
    "    for review in reviews:\n",
    "        darab = 0\n",
    "        darab = darab + len(review.find_all(\"span\", class_=\"star-display__filled\")) + 0.5*len(review.find_all(\"span\", class_=\"star-display__half\"))\n",
    "        review_text = review.find(\"p\", class_=\"audience-reviews__review js-review-text\").get_text().strip()\n",
    "        if [darab, review_text] not in lista:\n",
    "            lista = lista + [[darab, review_text]]\n",
    "\n",
    "    next_buttons = driver.find_elements(By.XPATH, \"//div[@class='prev-next-paging__wrapper']//rt-button[contains(@class, 'next')]\")\n",
    "    if len(next_buttons) == 0:\n",
    "        break\n",
    "\n",
    "    next_button = next_buttons[0]\n",
    "    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotten Tomatoes webscrape mentése picke-be\n",
    "with open('12 Angry Men Reviews Rotten Tomatoes.pkl', 'wb') as file:\n",
    "    pickle.dump(lista, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Egy Letterboxd filmhez az összes review letöltése\n",
    "\n",
    "numbers = [num for num in range(1, 1000)]\n",
    "lista2 = []\n",
    "\n",
    "url = letterboxdlinklist[4]\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "reviews = soup.find_all(\"li\", class_=\"film-detail\")\n",
    "\n",
    "for review in reviews:\n",
    "    div_element = review.find(\"div\", class_=\"attribution-block\")\n",
    "    span_element = div_element.find(\"span\")  \n",
    "    class_name = span_element.get(\"class\")\n",
    "    if class_name[0] == \"rating\":\n",
    "        darab =  int(class_name[-1].split(\"-\")[1])\n",
    "    else:\n",
    "       darab = \"Na\"\n",
    "    try:\n",
    "        review_text = review.find(\"div\", class_=\"body-text -prose collapsible-text\").find(\"p\").get_text().strip()\n",
    "    except AttributeError:\n",
    "        review_text = None\n",
    "    lista2 = lista2 + [[darab, review_text]]\n",
    "\n",
    "\n",
    "for i in numbers:\n",
    "\n",
    "    url = letterboxdlinklist[4] + \"page/\" + str(i) + \"/\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "    reviews = soup.find_all(\"li\", class_=\"film-detail\")\n",
    "\n",
    "    for review in reviews:\n",
    "        div_element = review.find(\"div\", class_=\"attribution-block\")\n",
    "        span_element = div_element.find(\"span\")  \n",
    "        class_name = span_element.get(\"class\")\n",
    "        if class_name[0] == \"rating\":\n",
    "            darab =  int(class_name[-1].split(\"-\")[1])\n",
    "        else:\n",
    "            darab = \"Na\"\n",
    "\n",
    "        #review_text = review.find(\"div\", class_=\"body-text -prose collapsible-text\").find(\"p\").get_text().strip()\n",
    "        try:\n",
    "            review_text = review.find(\"div\", class_=\"body-text -prose collapsible-text\").find(\"p\").get_text().strip()\n",
    "        except AttributeError:\n",
    "            review_text = None\n",
    "\n",
    "        lista2 = lista2 + [[darab, review_text]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letterboxd webscrape mentése picke-be\n",
    "with open('12 Angry Men Reviews Letterboxd.pkl', 'wb') as file:\n",
    "    pickle.dump(lista2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mentett pickle-ök beolvasása\n",
    "\n",
    "titles = ['The Shawshank Redemption',\n",
    " 'The Godfather',\n",
    " 'The Dark Knight',\n",
    " 'The Godfather Part II',\n",
    " '12 Angry Men']\n",
    "pages = ['IMDB', 'Rotten Tomatoes', 'Letterboxd']\n",
    "data = []\n",
    "for i in titles:\n",
    "    for j in pages:\n",
    "        data2 = []\n",
    "        try:\n",
    "            pickle_file_path = i + \" Reviews \" + j + \".pkl\"\n",
    "            with open(pickle_file_path, \"rb\") as file:\n",
    "                data2 = pickle.load(file)\n",
    "            for sublist in data2:\n",
    "                sublist.append(i)\n",
    "                sublist.append(j)\n",
    "                \n",
    "            data = data + data2\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {pickle_file_path} not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {pickle_file_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A letöltött és összefésült review-k filterezése, a kész df előállítása\n",
    "\n",
    "df_filterelőtt = pd.DataFrame(data)\n",
    "column_names = ['Score', 'Review', 'Movie', 'Page']\n",
    "df_filterelőtt.columns = column_names\n",
    "df_filterelőtt = df_filterelőtt.dropna(subset=['Review'])\n",
    "df_filterelőtt = df_filterelőtt[df_filterelőtt['Review'] != 'Na']\n",
    "df_filterelőtt['Length'] = df_filterelőtt.Review.str.len()\n",
    "df_filterelőtt['Wordcount'] = df_filterelőtt.Review.str.split().str.len()\n",
    "df_filterelőtt['Score'] = df_filterelőtt.apply(lambda row: row['Score'] * 2 if row['Page'] == 'Rotten Tomatoes' else row['Score'], axis=1)\n",
    "df_filterelőtt['Score'] = pd.to_numeric(df_filterelőtt['Score'], errors='coerce')\n",
    "df = df_filterelőtt[df_filterelőtt['Review'] != 'This review may contain spoilers. I can handle the truth.']\n",
    "\n",
    "\n",
    "z_scores = stats.zscore(df['Length'])\n",
    "threshold = 2\n",
    "threshold2 = 5\n",
    "filtered_df = df[abs(z_scores) < threshold]\n",
    "filtered_df2 = df[abs(z_scores) < threshold2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Itt következnek a különböző plotok, de elküldöm külön is:\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.boxplot(x='Page', y='Length', data=filtered_df, ax=axes[0])\n",
    "axes[0].set_title('Filtered DataFrame 1')\n",
    "sns.boxplot(x='Page', y='Length', data=filtered_df2, ax=axes[1])\n",
    "axes[1].set_title('Filtered DataFrame 2')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Movie', y='Score', hue='Page', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Box Plot of Movie Scores by Page')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lengths = df.groupby(['Movie', 'Page'])['Length'].mean().reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Movie', y='Length', hue='Page', data=avg_lengths)\n",
    "plt.title('Average Length by Movie and Page')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Page', data=df)\n",
    "plt.title('Bar Plot of Row Counts by Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Page', y='Score', data=df)\n",
    "plt.title('Bar Plot with Mean of Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Az általam épített algoritmusok közül a legjobb accuray score-ral rendelkező modell.(legalábbis egyelőre)\n",
    "#0.9398 valószínűséggel találja el a honlapot, igaz, a Rotten Tomatoes 80.2%-át adja a kritikáknak, ami növeli a magas találat esélyét.\n",
    "\n",
    "df = df.dropna()  \n",
    "features = df[['Movie', 'Score', 'Length', 'Review']]\n",
    "target = df['Page']\n",
    "\n",
    "text_preprocessor = TfidfVectorizer(preprocessor=WordNetLemmatizer().lemmatize)\n",
    "categorical_features = ['Movie']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_preprocessor, 'Review'),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A teljes és a filmekre lebontott confusion mátrxok alátámasztják, hogy a modellnek volt értelme. Az IMDB-t nagyon pontosan kitalálja, ami nem is meglepő.\n",
    "#Azonban a Letterboxd és a Rotten Tomatoes kritikák esetében is kevesebbszer lő mellé, mint amennyi a Letterboxd kritikák száma.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "movies = df['Movie'].unique()\n",
    "for movie in movies:\n",
    "    movie_mask = X_test['Movie'] == movie\n",
    "    movie_y_test = y_test[movie_mask]\n",
    "    movie_y_pred = y_pred[movie_mask]\n",
    "\n",
    "    cm = confusion_matrix(movie_y_test, movie_y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {movie}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szisz_ds_23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
